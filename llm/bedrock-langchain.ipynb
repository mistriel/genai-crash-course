{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LangChain\n",
    "LangChain is a framework for developing applications powered by language models. </br>\n",
    "It provides a standard interface for working with different LLM models, as well as tools for chaining together multiple LLM calls, managing memory, and more. </br>\n",
    "\n",
    "## Key Features\n",
    "- **Standard Interface**: LangChain provides a consistent interface for working with different LLMs, making it easier to switch between models.\n",
    "- **Chaining**: You can chain together multiple LLM calls to create complex workflows.\n",
    "- **Memory Management**: LangChain provides tools for managing memory, allowing you to store and retrieve information across multiple LLM calls.\n",
    "- **Tools and Utilities**: LangChain includes a variety of tools and utilities for working with LLMs, such as tokenizers, embeddings, and more.\n",
    "\n",
    "## Architecture\n",
    "LangChain's architecture is designed to be modular and extensible. It consists of several main packages:\n",
    "- **Core**: The core package provides the basic building blocks for working with LLMs, including the standard interface and utilities for chaining and memory management.\n",
    "- **langchain**: This package contains the main LangChain functionality, including the standard interface for LLMs, tools for chaining, and memory management.\n",
    "- **langchain_community**: This package contains community-contributed tools and utilities for working with LLMs, such as additional tokenizers, embeddings, and more.\n",
    "- **Integrations**: LangChain integrates with various LLM providers, allowing you to easily switch between different vendors.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "- https://python.langchain.com/docs/concepts/architecture/"
   ],
   "id": "84c337a228cd5180"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt Templates\n",
    "Prompt templates are a way to define the structure of a prompt that will be sent to an LLM. </br>\n",
    "They allow you to create reusable templates that can be filled in with specific values at runtime.\n",
    "\n",
    "### Types of Prompt Templates\n",
    "\n",
    "- **Simple Prompt Template**: A basic template that takes a single input and generates a prompt.\n",
    "- **Chat Prompt Template**: A template designed for chat-based interactions, allowing for multiple messages and roles.\n",
    "- **Few-Shot Prompt Template**: A template that includes examples of input-output pairs to guide the LLM's response.\n",
    "- **Custom Prompt Template**: A template that allows for more complex structures and custom formatting.\n",
    "- **Prompt Template with Variables**: A template that includes variables that can be filled in with specific values at runtime.\n",
    "- **Prompt Template with Conditionals**: A template that includes conditional logic to generate different prompts based on specific conditions."
   ],
   "id": "5aaa2ce4476f696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:44:49.674595Z",
     "start_time": "2025-05-29T13:44:47.944220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import Field\n",
    "# Import necessary libraries and Initialization steps\n",
    "#!pip install langchain>=0.3 langchain-community>=0.3 langchain-aws>=0.2 boto3==1.38.15 pydantic==2.10.4 faiss-cpu==1.11.0\n",
    "from enum import Enum\n",
    "from os import times\n",
    "\n",
    "import boto3\n",
    "from debugpy.launcher.debuggee import describe\n",
    "from langchain.retrievers.multi_query import LineListOutputParser\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "\n",
    "class LLMModel(Enum):\n",
    "    \"\"\"Enum for Bedrock models.\"\"\"\n",
    "    # Anthropic\n",
    "    CLAUDE_3_5_V1 = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "    CLAUDE_3_5_v2 = 'us.anthropic.claude-3-5-sonnet-20241022-v2:0' # Inference Profile ID\n",
    "    # Amazon\n",
    "    NOVA_LITE = 'amazon.nova-lite-v1:0'\n",
    "    NOVA_PRO = 'amazon.nova-pro-v1:0'\n",
    "    TITAN_LITE = 'amazon.titan-text-lite-v1'\n",
    "    TITAN_EXPRESS = 'amazon.titan-text-express-v1'\n",
    "    META_LLMA3_1B = 'meta.llama3-2-1b-instruct-v1:0'\n",
    "    META_LLMA3_3B = 'meta.llama3-2-3b-instruct-v1:0'\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    client=boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\"),\n",
    "    model = str(LLMModel.NOVA_PRO.value),\n",
    "    max_tokens=4096,\n",
    "    temperature=0.0,\n",
    ")"
   ],
   "id": "9faa7561651fef9d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:44:59.345274Z",
     "start_time": "2025-05-29T13:44:50.306374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate, ChatPromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "import json\n",
    "\n",
    "system_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that provides information about mobile phones available in the inventory.\n",
    "    The inventory is provided in JSON format. Use the information to answer customer queries.\n",
    "    The inventory is as follows:\n",
    "\n",
    "    {inventory}\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "assistant_message = AIMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Recommended guidelines for the assistant behavior:\n",
    "    - Do not recommend phones that are not available in the inventory.\n",
    "    - YOU MUST not recommend expensive phones beyond the customer's budget.\n",
    "    - Do not recommend phones that do not meet the customer's requirements.\n",
    "    - Suggest maximum 3 phones.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Customer: {customer_query}\n",
    "    \"\"\"\n",
    ")\n",
    "# Create a chat prompt template\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message, assistant_message, human_message]\n",
    ")\n",
    "\n",
    "with open('resources/mobile-phones-inventory.json', 'r') as file:\n",
    "    inventory = json.load(file)\n",
    "\n",
    "customer_query = \"I need a Android phone with a budget of maximum $500. Camera should be 50MP Wide, 8GB RAM, What do you have available?\"\n",
    "\n",
    "final_prompt = chat_prompt_template.format_messages(\n",
    "    inventory=json.dumps(inventory, indent=2),\n",
    "    customer_query=customer_query\n",
    ")\n",
    "\n",
    "print(llm.invoke(final_prompt).content)\n",
    "\n"
   ],
   "id": "d4e9da95255f705d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can recommend you some phones available in the inventory. Here are a few options that meet your requirements:\n",
      "\n",
      "1. **Aura Lite** by GloTech\n",
      "   - **RAM**: 8GB\n",
      "   - **Storage**: 128GB\n",
      "   - **Main Camera**: 48MP Wide, 8MP Ultra-Wide, 2MP Macro\n",
      "   - **Selfie Camera**: 16MP\n",
      "   - **Price**: $499.99\n",
      "\n",
      "2. **Chronos Mini** by TimeWare\n",
      "   - **RAM**: 6GB\n",
      "   - **Storage**: 64GB\n",
      "   - **Main Camera**: 50MP Wide, 8MP Ultra-Wide\n",
      "   - **Selfie Camera**: 12MP\n",
      "   - **Price**: $349.0\n",
      "\n",
      "3. **Terra Explorer** by Rugged Phones Inc.\n",
      "   - **RAM**: 8GB\n",
      "   - **Storage**: 128GB\n",
      "   - **Main Camera**: 48MP Wide, 2MP Depth\n",
      "   - **Selfie Camera**: 16MP\n",
      "   - **Price**: $699.0\n",
      "\n",
      "These options are within your budget and meet the camera specifications you're looking for. Please let me know if you need more information or have other preferences.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Output Parsers\n",
    "Output parsers are used to process the output from an LLM and convert it into a structured format. </br>\n",
    "The combination of Pydantic and LangChain allows you to define data models that can be used to validate and parse the output from an LLM."
   ],
   "id": "d72482c2d6985190"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:45:06.567444Z",
     "start_time": "2025-05-29T13:44:59.364747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class PhoneRecommendation(BaseModel):\n",
    "    \"\"\"Model for phone recommendation.\"\"\"\n",
    "    brand: str\n",
    "    model: str\n",
    "    price: float\n",
    "    camera: str\n",
    "    ram: str\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=PhoneRecommendation)\n",
    "\n",
    "system_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that provides information about mobile phones available in the inventory.\n",
    "    The inventory is provided in JSON format. Use the information to answer customer queries.\n",
    "    The inventory is as follows:\n",
    "\n",
    "    {inventory}\n",
    "\n",
    "    ---------------------\n",
    "\n",
    "    The output should be a JSON array of phone recommendations, each recommendation should be a JSON object with the following fields:\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message, assistant_message, human_message]\n",
    ")\n",
    "final_prompt = chat_prompt_template.format_messages(\n",
    "    inventory=json.dumps(inventory, indent=2),\n",
    "    customer_query=customer_query,\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "print(llm.invoke(final_prompt).content)\n",
    "\n"
   ],
   "id": "4eb61c2ac04b45d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have the following phones that match your requirements:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"brand\": \"TimeWare\",\n",
      "        \"model\": \"TM-CP3\",\n",
      "        \"price\": 649,\n",
      "        \"camera\": \"50MP Wide\",\n",
      "        \"ram\": \"8GB\"\n",
      "    },\n",
      "    {\n",
      "        \"brand\": \"TimeWare\",\n",
      "        \"model\": \"TM-C2\",\n",
      "        \"price\": 349,\n",
      "        \"camera\": \"50MP Wide\",\n",
      "        \"ram\": \"6GB\"\n",
      "    },\n",
      "    {\n",
      "        \"brand\": \"TechCo\",\n",
      "        \"model\": \"TS-2025\",\n",
      "        \"price\": 799.99,\n",
      "        \"camera\": \"50MP Wide\",\n",
      "        \"ram\": \"8GB\"\n",
      "    },\n",
      "    {\n",
      "        \"brand\": \"BrightStar\",\n",
      "        \"model\": \"BS-LG3\",\n",
      "        \"price\": 599,\n",
      "        \"camera\": \"50MP Wide\",\n",
      "        \"ram\": \"8GB\"\n",
      "    },\n",
      "    {\n",
      "        \"brand\": \"Zenith Mobile\",\n",
      "        \"model\": \"ZPM-M2\",\n",
      "        \"price\": 749,\n",
      "        \"camera\": \"50MP Wide\",\n",
      "        \"ram\": \"8GB\"\n",
      "    },\n",
      "    {\n",
      "        \"brand\": \"Harmony Devices\",\n",
      "        \"model\": \"HD-ZF\",\n",
      "        \"price\": 399,\n",
      "        \"camera\": \"48MP Wide\",\n",
      "        \"ram\": \"6GB\"\n",
      "    }\n",
      "]\n",
      "\n",
      "Please note that the phones listed above may not meet your budget of $500. I have listed all the phones that meet your other requirements, but you may need to consider increasing your budget to get a phone with the specifications you want.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Memory\n",
    "Memory in LangChain allows you to store historical messages and context across multiple interactions with an LLM. </br>\n",
    "This is particularly useful for chat-based applications where you want to maintain **context** & **continuity** in conversations.\n",
    "\n",
    "### Types of Memory\n",
    "- **In-Memory Memory**: Stores messages in memory, suitable for short-lived applications.\n",
    "- **Persistent Memory**: Stores messages in a database or file system, suitable for long-lived applications.\n",
    "- **Custom Memory**: Allows you to implement your own memory management logic, suitable for complex applications.\n"
   ],
   "id": "5aa79b5fa74f7635"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:45:21.673654Z",
     "start_time": "2025-05-29T13:45:06.579776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import uuid\n",
    "\n",
    "# MessagesPlaceholder is used to dynamically include the message history in the prompt.\n",
    "history_message = MessagesPlaceholder(variable_name=\"history\")\n",
    "\n",
    "# Create a chat prompt template with system, history, and human messages\n",
    "# And the partial method is used to fill in the inventory data that is known at the time of creating the prompt template.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message, assistant_message, history_message, human_message]).partial(\n",
    "    inventory=json.dumps(inventory, indent=2, ), format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "# Combine the chat prompt template with the LLM to create a runnable\n",
    "# The pipe operator (|) is used to chain operations, where the output of chat_prompt_template (partial formatted messages) becomes the input for llm.\n",
    "# This allows seamless integration of the prompt template with the language model for generating responses.\n",
    "runnable = chat_prompt_template | llm\n",
    "\n",
    "# Create a message history store (in memory for this example)\n",
    "sessions = {}\n",
    "\n",
    "# create sessions with unique session IDs to manage conversation history\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in sessions:\n",
    "        sessions[session_id] = InMemoryChatMessageHistory()\n",
    "    return sessions[session_id]\n",
    "\n",
    "# Use the runnable with message history\n",
    "chat_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"customer_query\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "def interactive_chat():\n",
    "    session_id = str(uuid.uuid4())\n",
    "\n",
    "    response = None\n",
    "    while True:\n",
    "        # Set the AI message to the initial greeting or the last response\n",
    "        ai_message = response.content if response else \"Sales Assistant: Hello! I'm your phone sales representative. How can I help you today?\"\n",
    "        # Get the user query\n",
    "        user_input = input(ai_message)\n",
    "\n",
    "        # Check if user wants to exit\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"\\nSales Assistant: Thank you for shopping with us! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        # Get response using the runnable with history\n",
    "        response = chat_with_history.invoke(\n",
    "            {\"customer_query\": user_input},\n",
    "            {\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "\n",
    "        print(\"Tokens used so far:\", response.usage_metadata['total_tokens'])\n",
    "\n",
    "# Run the interactive conversation\n",
    "interactive_chat()\n"
   ],
   "id": "da205dc17e830940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens used so far: 15630\n",
      "\n",
      "Sales Assistant: Thank you for shopping with us! Have a great day!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Retrieval-Augmented Generation (RAG)\n",
    "Retrieval-Augmented Generation (RAG) is a technique that combines the power of large language models (LLMs) with external knowledge sources to improve the quality and relevance of generated responses. </br>\n",
    "\n",
    "The process of creating a RAG application typically involves the following steps:\n",
    "1. **Document Loading**: Load documents from various sources (e.g., web pages, documents, databases) that contain relevant information.\n",
    "2. **Chunking**: Split the loaded documents into smaller, manageable chunks to facilitate efficient retrieval.\n",
    "3. **Embedding Creation**: Generate embeddings for the document chunks using a suitable embedding model. These embeddings capture the semantic meaning of the text.\n",
    "4. **Vector Store Creation**: Store the embeddings in a vector store (e.g., FAISS, Pinecone) to enable efficient similarity search.\n",
    "5. **Retriever Creation**: Create a retriever that can query the vector store to find relevant document chunks based on user queries.\n",
    "\n",
    "\n",
    "### Embeddings and Vector Stores\n",
    "Embeddings are numerical representations of text that capture semantic meaning. </br>\n",
    "In order to create an embedding vector, we use a LLM to convert text into a high-dimensional vector space where similar texts are closer together. </br>\n",
    "Once we have the embeddings, we store them in a vector store for future retrival. </br>\n",
    "\n",
    "![RAG Indexing Process](../resources/images/rag_indexing.png)\n",
    "\n",
    "### Retrieval and generation\n",
    "\n",
    "When using trying to find similar documents, we use a retriever to search the vector store for relevant chunks based on the user's query. </br>\n",
    "For that the query is also converted into an embedding vector using the same embedding model. </br>\n",
    "Now that we have both chunks and query in the same vector space, we can find the most similar chunks to the query. </br>\n",
    "\n",
    "![RAG Indexing Process](../resources/images/rag_retrieval_generation.png)\n",
    "\n",
    "References:\n",
    "- https://python.langchain.com/docs/tutorials/rag/"
   ],
   "id": "7038623de3d03018"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:47:01.567763Z",
     "start_time": "2025-05-29T13:45:21.710256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_aws import BedrockEmbeddings  # Changed LLM import\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- 1. Load and Chunk Documents ---\n",
    "print(\"Step 1: Loading webpage content by known element ids\")\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\"),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "if not docs:\n",
    "    print(\"No documents loaded. Check the URL or SoupStrainer.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Step 2: Splitting documents into chunks...\")\n",
    "\n",
    "# RecursiveCharacterTextSplitter Is Recommended for general text:\n",
    "# This is a more sophisticated and generally recommended splitter for generic text.\n",
    "# It attempts to keep semantically related pieces of text together by using a list of separators in a hierarchical order.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Step 2: Document was split into {len(all_splits)} chunks.\")\n",
    "\n",
    "if not all_splits:\n",
    "    print(\"No text splits generated. Check the document content or splitter settings.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Create Vector Store and Index Chunks ---\n",
    "print(\"\\nStep 3: Creating vector store and indexing chunks with AWS Bedrock Embeddings...\")\n",
    "# Instantiate BedrockEmbeddings\n",
    "embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v2:0')\n",
    "\n",
    "# InMemoryVectorStore is suitable for small datasets, testing and quick prototyping.\n",
    "vector_store = InMemoryVectorStore.from_documents(documents=all_splits, embedding=embeddings)\n",
    "# Or use FAISS for larger datasets with very quick response time.\n",
    "# vector_store = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "print(\"Vector store created and documents indexed successfully using AWS Bedrock Embeddings.\")"
   ],
   "id": "a3d7aeac90046757",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading webpage content by known element ids\n",
      "Step 2: Splitting documents into chunks...\n",
      "Step 2: Document was split into 61 chunks.\n",
      "\n",
      "Step 3: Creating vector store and indexing chunks with AWS Bedrock Embeddings...\n",
      "Vector store created and documents indexed successfully using AWS Bedrock Embeddings.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lets explore the process for:\n",
    "1. Chunks of text Created from the document\n",
    "2. Embedding vectors created for each chunk\n",
    "3. Vector Store created with the embeddings\n"
   ],
   "id": "e58aa5b823751740"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:47:11.542133Z",
     "start_time": "2025-05-29T13:47:11.372475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lets see the raw document content\n",
    "print(docs)\n",
    "\n",
    "# Find similar chunks of text based on similarity to a query\n",
    "vector_store.similarity_search(\"What is an LLM agent?\", k=3)\n",
    "\n",
    "# Display the first few chunks of text\n",
    "print(\"\\n--- Text Chunks ---\")\n",
    "for i, chunk in enumerate(all_splits[:5]):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(\"MetaData: \\n\", chunk.metadata)\n",
    "    print(\"Content: \\n\",chunk.page_content)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# The question will be converted into an embedding vector and used to search the vector store.\n",
    "## Print the first few embedding vectors\n",
    "print('The embedding vector of the question', embeddings.embed_query(\"Describe an LLM agent?\") )\n",
    "# vector_store.similarity_search(\"What is an LLM agent?\", k=3)  # Example search to see if the vector store works"
   ],
   "id": "e18b9febce88ad5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding vector of the question [-0.04635310545563698, 0.04474901780486107, 0.012986388057470322, 0.032879702746868134, 0.022400513291358948, -0.10891260206699371, -0.005692922044545412, -0.007107878103852272, -0.034674108028411865, -0.03299909085035324, 0.03470158949494362, 0.04468252509832382, 0.06264342367649078, -0.00245459983125329, -0.016014890745282173, -0.02178206294775009, -0.03205105662345886, 0.01426776871085167, 0.0674503743648529, 0.037971239537000656, -0.015511320903897285, -0.024785960093140602, -0.007201262749731541, 0.02516615018248558, -0.003227092558518052, -0.020350778475403786, 0.015962878242135048, -0.011779478751122952, 0.005106608383357525, 0.022048253566026688, 0.03626164421439171, 0.07185068726539612, 0.02995876781642437, -0.0451178252696991, -0.0007849045214243233, 0.017579972743988037, 0.02209361456334591, 4.244424417265691e-05, 0.042321011424064636, -0.011768840253353119, -0.0196001548320055, 0.02756090648472309, -0.001407420146279037, -0.009589075110852718, 0.020740866661071777, 0.0030355947092175484, 0.005032137036323547, 0.002115341369062662, -0.00679492112249136, 0.02845626138150692, -0.0015340510290116072, 0.040831584483385086, -0.06099086254835129, 0.11450859159231186, 0.048071857541799545, 0.027722259983420372, -0.03863290697336197, -0.06259112060070038, -0.015394294634461403, -0.010700235143303871, -0.050534144043922424, 0.024580279365181923, 0.03796207532286644, 0.03537331148982048, -0.0327177532017231, -0.03413389250636101, 0.04823380336165428, 0.04833487048745155, 0.036211997270584106, 0.05446339026093483, -0.024838194251060486, -0.016270222142338753, 0.04808013141155243, -0.006007357034832239, 0.06640008836984634, -0.03246951848268509, 0.06865078210830688, -0.009366842918097973, -0.02814958430826664, 0.010609214194118977, 0.001751850126311183, 0.06511634588241577, 0.05704270303249359, 0.040658414363861084, 0.029984772205352783, -0.06678308546543121, 0.012042603455483913, -0.023859206587076187, 0.00798557698726654, -0.03625691682100296, 0.022750411182641983, -0.03229811415076256, -0.019297540187835693, -0.02352585829794407, -0.005338887684047222, -0.05559346452355385, 0.00865995604544878, -0.017765188589692116, 0.0233408622443676, -0.020205972716212273, -0.004884375724941492, -0.012942058965563774, 0.01283109188079834, -0.07878360897302628, -0.012414554134011269, 0.018795153126120567, 0.04222053661942482, 0.02645152062177658, 0.021097559481859207, 0.017410343512892723, 0.05487712100148201, 0.03640349581837654, 0.016717050224542618, -0.055323950946331024, -0.036181263625621796, -5.6149045121856034e-05, 0.00767646124586463, 0.0280910711735487, 0.012986091896891594, -0.07222067564725876, -0.023363322019577026, 0.05141124874353409, -0.049700770527124405, -0.012799618765711784, 0.02512049302458763, -0.030291521921753883, 0.002477059606462717, -0.009678174741566181, -0.01028355024755001, 0.03334241360425949, 0.032201480120420456, 0.03707019239664078, 0.011842720210552216, -0.019102053716778755, -0.02175169810652733, -0.011530059389770031, -0.04315054044127464, 0.045815255492925644, 0.06580136716365814, -0.01597144827246666, 0.0013262996217235923, -0.055269576609134674, 0.025116944685578346, 0.016974743455648422, -0.02797049842774868, -0.0271855928003788, 0.01844244822859764, -0.021840205416083336, -0.0032944714184850454, 0.01367495208978653, -0.005283920560032129, -0.03299436345696449, -0.037561941891908646, 0.01967344433069229, 0.016257809475064278, 0.03855843469500542, -0.02785288169980049, 0.035299427807331085, -0.03235367313027382, -0.026755906641483307, 0.014540829695761204, 0.0013017712626606226, 0.016065720468759537, 0.050622206181287766, 0.04064600169658661, 0.022069530561566353, -0.04773643985390663, 0.02631085179746151, -0.013078589923679829, 0.021029295399785042, 0.08409944921731949, 0.019974876195192337, -0.04855532944202423, 0.06474517285823822, -0.02229885570704937, 0.05804038047790527, -0.02139219455420971, -0.013114052824676037, -0.008094919845461845, 0.009995711967349052, -0.030381066724658012, 0.023747462779283524, -0.01659850776195526, -0.0023239795118570328, 0.02572690136730671, 0.020071806386113167, 0.002011761302128434, 0.006783247925341129, -0.04565863311290741, -0.045401524752378464, -0.001751850126311183, 0.02802487462759018, -0.0029937783256173134, -0.02986183576285839, 0.025885893031954765, 0.030306300148367882, -0.01319207064807415, -0.00941575225442648, -0.059676386415958405, -0.008982664905488491, -0.026389461010694504, -0.007444772403687239, -0.0364094078540802, 0.0029351175762712955, -0.01885189488530159, -0.05627434328198433, -0.0037448459770530462, 0.001988267293199897, 0.0327177532017231, 0.00817057304084301, 0.05216069146990776, -0.022762231528759003, 0.028594641014933586, 0.048016298562288284, -0.0036644639912992716, -0.0322478748857975, 0.009983891621232033, -0.007111424580216408, -0.021140411496162415, 0.03335608169436455, 0.007953069172799587, 0.04626031219959259, -0.04962807521224022, -0.007009765133261681, 0.019637981429696083, -0.021354664117097855, 0.047250308096408844, 0.006090102717280388, -0.001217547687701881, -0.005418087355792522, 0.015872154384851456, 0.041841086000204086, 0.03204869478940964, -0.006495558191090822, -0.06263396888971329, -0.032628580927848816, -0.022646388038992882, -0.005772713106125593, -0.004645594861358404, -0.0027725808322429657, 0.00019386196800041944, 0.04158103093504906, -0.041141293942928314, 0.05200347304344177, 0.02764306217432022, 0.006684691179543734, -0.023209061473608017, -0.010037676431238651, 0.025932583957910538, -0.06975247710943222, -0.04255979508161545, 0.0007872687419876456, 0.024525903165340424, -0.04962393641471863, -0.028679750859737396, 0.0020302312914282084, -0.009664728306233883, 0.00024823789135552943, 0.028569519519805908, -0.00021927680063527077, 0.00527210021391511, -0.03782672807574272, -0.0004403267230372876, -0.009111512452363968, 0.01514886412769556, 0.03555357828736305, 0.044941697269678116, -0.0023387554101645947, -0.031287431716918945, -0.006798171438276768, 0.039044272154569626, 0.02837122604250908, 0.030511390417814255, 0.01915687322616577, 0.025467433035373688, 0.004173942841589451, -0.056710533797740936, 0.030270835384726524, -0.025121673941612244, 0.01190005149692297, 0.0014445080887526274, -0.021561235189437866, 0.00590274203568697, 0.01884480193257332, 0.015137782320380211, 0.0029091117903590202, 0.0005319383344613016, 0.007316220551729202, 0.010527650825679302, 0.015875404700636864, -0.00945668201893568, 0.04406813532114029, -0.0401252917945385, -0.012163656763732433, 0.02850480191409588, 0.016158513724803925, 0.06156772002577782, 0.03847923502326012, 0.004249596036970615, -0.006659867707639933, 0.014379475265741348, 0.015373017638921738, -0.007638043258339167, -0.010747518390417099, 0.03717421367764473, -0.0062650516629219055, 0.017057599499821663, 0.023487146943807602, 0.005757936742156744, 0.03516940027475357, 0.0025462114717811346, 0.014174973592162132, 0.046424031257629395, -0.019693538546562195, 0.0018629662226885557, -0.018757328391075134, 0.010352701880037785, -0.01314449217170477, 0.012025352567434311, 0.04407522827386856, 0.012785432860255241, 0.004536252003163099, 0.047437671571969986, 0.029140762984752655, 0.016497181728482246, 0.06377585977315903, 0.030575813725590706, -0.0008463729755021632, -0.004971850197762251, -0.03612448647618294, 0.001553851063363254, -0.00612792931497097, -0.018407432362437248, -0.024830881506204605, -0.03672398626804352, 0.046654537320137024, 0.02389555796980858, -0.00734303891658783, -0.04629015922546387, 0.016046954318881035, 0.0032791041303426027, 0.00293157109990716, 0.02299163118004799, -0.021302355453372, -0.010611874051392078, -0.044120147824287415, -0.01216631568968296, -0.040722835808992386, -0.016988927498459816, -0.011962701566517353, -0.004173351917415857, -0.03459253907203674, 0.07583549618721008, -0.05846179649233818, -0.00022681259724777192, 0.0026112261693924665, 0.004256097599864006, -0.009041769430041313, 0.02057773992419243, 0.05808640643954277, 0.032738737761974335, 0.006914607249200344, -0.03650279343128204, -0.009336109273135662, -0.039524197578430176, 0.04180798679590225, -0.011298961006104946, -0.0359637588262558, -0.040180254727602005, 0.00041136564686894417, -0.01297929510474205, 0.025712715461850166, 0.03663282096385956, 0.015380701050162315, 0.002322797430679202, 0.0075038764625787735, 0.04420466721057892, 0.037469737231731415, -0.028270749375224113, 0.0578748881816864, -0.04890641197562218, -0.006466005928814411, -0.03376626595854759, 0.024363957345485687, 0.03132688254117966, -0.025145020335912704, -0.0052961851470172405, 0.04308168590068817, -0.04501143842935562, -0.032150786370038986, -0.008078370243310928, -0.005878509487956762, -0.030296841636300087, -0.012001710943877697, 0.007142158690840006, -0.027768362313508987, -0.047451261430978775, 0.014095183461904526, 0.02440769597887993, 0.009571638889610767, -0.04748081788420677, 0.04507586359977722, 0.048917047679424286, -0.034402817487716675, 0.020179376006126404, -0.07982857525348663, 0.019797563552856445, -0.041500646620988846, -0.04974096268415451, -0.01062931027263403, -0.0357167050242424, 0.030835576355457306, 0.020857302471995354, 0.021785831078886986, -0.005144434981048107, -0.012715689837932587, -0.02706502191722393, 0.0254290159791708, -0.06339050084352493, 0.03909924253821373, 0.008417628705501556, -0.034502703696489334, -0.02148238569498062, 0.00019859030726365745, -0.0022495081648230553, -0.041107453405857086, -0.005243729799985886, -0.02046898752450943, 0.030537988990545273, -0.020386241376399994, -0.055191557854413986, -0.002471370855346322, 0.03990482911467552, 0.007174074649810791, -0.029197504743933678, 0.023183055222034454, -0.10077217221260071, -0.05695522949099541, 0.0062759858556091785, 0.019238730892539024, -0.022435976192355156, -0.05297219008207321, 0.04224151745438576, -0.011255815625190735, 0.0007695374661125243, -0.01956232823431492, 0.05287230759859085, -0.00713270204141736, -0.01175465527921915, -0.018671033903956413, 0.007916332222521305, -0.02585870400071144, 0.018245484679937363, -0.02580728381872177, 0.01275469921529293, -0.00046337739331647754, -0.012890342622995377, -0.0004681057471316308, -0.034073606133461, -0.016187475994229317, 0.00581319909542799, -0.00504277553409338, 0.02579309791326523, -0.005392672494053841, 0.013742922805249691, -0.043195754289627075, -0.009116832166910172, 0.02235323004424572, 0.0330345518887043, -0.036752209067344666, 0.033396270126104355, -0.063872791826725, 0.03365396708250046, -0.007265095133334398, -0.04755173996090889, -5.319383126334287e-05, 0.06200036406517029, -0.036597948521375656, -0.03445069119334221, 0.015339919365942478, 0.08419874310493469, -0.024634653702378273, 0.010697871446609497, 0.02457060106098652, 0.05535231903195381, -0.005404493771493435, 0.02876604162156582, 0.013472224585711956, -0.037554845213890076, -0.02297636680305004, -0.0033937664702534676, -0.006571507081389427, 0.007828950881958008, 0.03420688584446907, 0.0022666482254862785, 0.006893920712172985, 0.005056960508227348, -0.01247454434633255, -0.01470572967082262, -0.015453399159014225, 0.022752776741981506, 0.006509743165224791, 0.004710609558969736, 0.0384848527610302, -0.004406813532114029, -0.06391771137714386, -0.023951411247253418, -0.0014894272899255157, -0.06406784057617188, 0.004626681562513113, -0.07614283263683319, -0.030863061547279358, -0.037530023604631424, -0.02995315007865429, -0.04576560854911804, -0.032661013305187225, -0.01578615792095661, -0.030829962342977524, 0.0199465062469244, 0.0006146843079477549, 0.019918134436011314, -0.025972776114940643, -0.009921240620315075, 0.03316221758723259, -0.016168856993317604, -0.00831005908548832, -0.0023665346670895815, -0.03184537589550018, -0.04924212023615837, 0.0414959155023098, -0.02293422445654869, 0.01668749563395977, 0.0637143924832344, 0.008354978635907173, -0.011162430047988892, 0.0007541703525930643, 0.02288753353059292, -0.01305258460342884, -0.06503833085298538, -0.024458523839712143, 0.0027424374129623175, -0.00025651248870417476, -0.020336594432592392, 0.047505639493465424, 0.010090279392898083, -0.016556285321712494, 0.0503237284719944, 0.07356825470924377, 0.01293082907795906, 0.02874979004263878, 0.023793010041117668, -0.03190920874476433, 0.002571035409346223, 0.00045842741383239627, 0.040637727826833725, 0.01994059607386589, 0.08343630284070969, 0.006625587586313486, -0.014540829695761204, 0.031287431716918945, 0.006157185882329941, -0.06198795139789581, -0.030332306399941444, 0.005108972545713186, 0.015655536204576492, -0.014466358348727226, -0.001411409699358046, -0.04386599734425545, -0.01953159272670746, -0.014244717545807362, -0.013186159543693066, 0.016996020451188087, -0.029188046231865883, 0.006361982319504023, 0.0094560906291008, 0.04560602828860283, 0.018460623919963837, -0.026509443297982216, -0.05199756100773811, -0.01503375917673111, -0.029669156298041344, 0.00726745929569006, -0.022678082808852196, -0.0031608957797288895, 0.01374528557062149, 0.014610277488827705, 0.003177444916218519, 0.00902462936937809, 0.008577209897339344, -0.039725154638290405, 0.03228038176894188, -0.05406266450881958, 0.0011525331065058708, -0.021288173273205757, -0.03739674389362335, 0.015548408962786198, -0.03834979981184006, -0.02634158544242382, 0.022889897227287292, -0.0259585902094841, -0.02883342280983925, 0.07882380485534668, 0.0035840822383761406, -0.054910220205783844, -0.022175917401909828, -0.020456574857234955, -0.06882867962121964, 0.004013179335743189, 0.024666571989655495, 0.055205151438713074, -0.027017148211598396, -0.06761527806520462, 0.061312392354011536, 0.007242635823786259, -0.01136220246553421, 0.031069926917552948, 0.036239780485630035, -0.004567577037960291, 0.02707684226334095, -0.0359342098236084, 0.005755572579801083, 0.011116329580545425, -0.03937525674700737, -0.012654886581003666, 0.011442584916949272, 0.055693354457616806, 0.00038299558218568563, -0.025765910744667053, -0.045335330069065094, 0.009972070343792439, -0.04260234907269478, 0.025246385484933853, -0.02730143815279007, 0.027857020497322083, 0.032558172941207886, -0.0008688325760886073, -0.019426388666033745, -0.04509536549448967, 0.020233752205967903, 0.01992877386510372, -0.018670298159122467, 0.017905892804265022, 0.02480960264801979, 0.056436292827129364, -0.004062512889504433, 0.029045606032013893, 0.022647570818662643, -0.02324511483311653, -0.014239397831261158, -0.011330507695674896, 0.029615961015224457, 0.005173395853489637, 0.02167944237589836, -0.017744872719049454, 0.021615609526634216, 0.02001092955470085, -0.025012921541929245, -0.01433751080185175, -0.009308329783380032, -0.02043057046830654, -0.038108061999082565, -0.008642815984785557, 0.047184109687805176, 0.004693173803389072, -0.0034469603560864925, 0.027268338948488235, -0.02420496754348278, -0.008111468516290188, -0.03174608200788498, 0.004633774049580097, 0.021799718961119652, -0.008021630346775055, -0.050765831023454666, -0.027802642434835434, -0.05948725342750549, 0.03223767876625061, 0.08676978200674057, -0.024431336671113968, 0.003995447885245085, 0.04615717753767967, 0.016388429328799248, -0.04218714311718941, -0.004037411883473396, 0.04564385488629341, 0.0036904329899698496, 0.006361982319504023, 0.008847908116877079, 0.01812845841050148, -0.0689983144402504, 0.021225521340966225, 0.038824405521154404, 0.013253538869321346, -0.02231776714324951, 0.004496060777455568, -0.04246179386973381, 0.023888759315013885, 0.01192723959684372, -0.01259629987180233, -0.02518550679087639, -0.031549856066703796, 0.021974964067339897, -0.007380939554423094, 0.009074867703020573, 0.04537079483270645, -0.0074178799986839294, -0.033791087567806244, -0.030131349340081215, 0.03954548016190529, -0.07334324717521667, 0.03089497797191143, -0.03727941960096359, -0.040247637778520584, -0.014229940250515938, 0.03489752113819122, -0.010288869962096214, 0.04832009598612785, 0.03143748268485069, -0.015371834859251976, 0.047938283532857895, -0.003567532869055867, 0.01631159521639347, 0.00041254772804677486, 0.039122290909290314, -0.02603187970817089, 0.019267989322543144, -0.005347753409296274, 0.007239089347422123, -0.05412295088171959, 0.027510669082403183, 0.03098599798977375, 0.03282768651843071, 0.02106475830078125, -0.023965004831552505, -0.0001730277290334925, 0.05297987535595894, -0.07678322494029999, 0.05054399371147156, 0.020454801619052887, -0.04178907349705696, -0.02857070416212082, -0.025194963440299034, 0.029530851170420647, -0.005697650369256735, 0.015962878242135048, -0.013412529602646828, -0.05800255388021469, -0.047700684517621994, 0.054575689136981964, 0.02042938582599163, 0.0008534655207768083, -0.011366930790245533, -0.0054163141176104546, 0.02602449245750904, 0.0006253230385482311, 0.023263804614543915, -0.0330936573445797, 0.02228880673646927, 0.01450182031840086, 0.019616998732089996, -0.033798474818468094, -0.023232702165842056, 0.007191806100308895, -0.0207680556923151, 0.010978467762470245, 0.01572468876838684, 0.0069583444856107235, 0.008983846753835678, -0.05731457844376564, 0.0555887371301651, 0.016709957271814346, -0.015650808811187744, 0.005220088176429272, -0.004674112424254417, -0.029693979769945145, -0.04147936776280403, -0.02989020384848118, -0.01894587092101574, 0.009385757148265839, 0.01785421557724476, -0.011085594072937965, 0.009084325283765793, -0.009693099185824394, -0.0017766739474609494, 0.002273519290611148, -0.03345537558197975, 0.00909732747823, -0.003208179259672761, 0.0060430411249399185, -0.008297055959701538, -0.03597838804125786, 0.006250866688787937, -0.039907194674015045, 0.014057356864213943, -0.07241512835025787, 0.01091182790696621, 0.018386153504252434, -0.0003404405142646283, 0.03237022086977959, 0.045997295528650284, -0.055567461997270584, -0.01294856145977974, 0.0010059544583782554, -0.013177885673940182, 0.014099911786615849, 0.035111475735902786, -0.03829837962985039, -0.001962852431461215, 0.049472223967313766, 0.025206489488482475, -0.020666396245360374, 0.03620372340083122, -0.003646732773631811, 0.015789702534675598, 0.03806314244866371, -0.06841791421175003, -0.026619376614689827, -0.004899004474282265, -0.0026295483112335205, -0.0031201138626784086, 0.015380109660327435, 0.03361082077026367, -0.08451909571886063, 0.002795631531625986, -0.024702033028006554, -0.04023995250463486, 0.01681634411215782, 0.010284732095897198, -3.3689429983496666e-05, -0.004822907503694296, 0.053768619894981384, -0.044447582215070724, -0.00941649079322815, 0.07331971824169159, 0.012397709302604198, 0.03673920780420303, -0.034222546964883804, -0.003625455079600215, -0.004961211234331131, 0.04692642018198967, -0.02403179183602333, 0.0681605264544487, -0.007482599001377821, -0.003608905943110585, 0.007711923681199551, -0.05238291993737221, 0.006085374392569065, -0.009033494628965855, -0.04773939773440361, 0.029902026057243347, 0.0039056092500686646, -0.0018558737356215715, 0.05225437134504318, -0.0002588766801636666, -0.0036029955372214317, -0.01709708943963051, -0.011179570108652115, 0.0049269311130046844, -0.0485222302377224, 0.0028398120775818825, -0.01456328947097063, 0.021688899025321007, -0.01636005938053131, -0.006370256654918194, 0.02019001543521881, -0.002137209987267852, 0.01717481203377247, 0.028721123933792114, -0.024762321263551712, -0.007094875443726778, -0.03175080940127373, 0.007073006592690945, 0.056267254054546356, 0.017733052372932434, -0.08725325018167496, -0.007337202783674002, 0.07512151449918747, -0.02775920182466507, -0.025219786912202835, 0.05455559492111206, 0.040718697011470795, -0.018957100808620453, 0.04832807555794716, -0.008883961476385593, 0.008513377979397774, -0.017079506069421768, 0.017746053636074066, 0.011319647543132305, 0.037201400846242905, 0.011350973509252071, -0.010092051699757576, -0.002056828234344721, 0.03485378250479698, -0.0010027037933468819, -0.03300677239894867, -0.01867280900478363, -0.0883963331580162, -0.03030984476208687, -0.008332518860697746, 0.039657775312662125, 0.04994073510169983, -0.04865462705492973, 0.010695950128138065, 0.006210675463080406, 0.046143874526023865, 0.030573450028896332, -0.003981262911111116, 0.004605403635650873, 0.010475639253854752, -0.02345966175198555, 0.019421659409999847, 0.013189706020057201, 0.02134372852742672, -0.014670267701148987, 0.005692922044545412, 0.010244540870189667, -0.009243905544281006, 0.01175465527921915, -0.001815682859160006, 0.003017863491550088, 0.03355230763554573, -0.01678561046719551, -0.029712893068790436, 0.02280973643064499, 0.012440264225006104, -0.0262801181524992, 0.007196534425020218, 0.028594493865966797, 0.0036644639912992716, -0.018528003245592117, 0.01195797324180603, 0.0680479109287262, 0.025816740468144417, 0.03757848963141441, 0.011566704139113426, 0.021646343171596527, 0.03174135088920593, -0.025737538933753967, 0.004387900233268738, 0.010518193244934082, 0.008366798982024193, 0.06627243012189865, 0.003503700252622366, -0.01360816415399313, 0.016953466460108757, -0.03667773678898811, 0.004730114247649908, 0.0009964978089556098, 0.01755337417125702, 0.010298325680196285, 0.008825448341667652, 0.02922823652625084, -0.05373581871390343, 0.0013354606926441193, -0.040492620319128036, -0.015343465842306614, 0.003976534586399794, 0.05130958557128906, 0.041967567056417465, 7.801762694725767e-05, 0.03459253907203674, -0.010723876766860485, -0.032430730760097504, 0.006580520421266556, -0.0177791528403759, 0.06059250235557556, -0.01157497800886631, 0.048782069236040115, 0.007582780905067921, 0.0030497799161821604, -0.02158132940530777, 0.034012727439403534, -0.00879500899463892, -0.01866276003420353, -0.0067603448405861855, 0.002161442767828703, -0.022166460752487183, -0.02549639344215393, -0.005912790074944496, -0.015354104340076447, -0.06268125027418137, 0.05850611999630928, 0.011508781462907791, 0.0027510079089552164, -0.0212775319814682, -0.023767003789544106, -0.03123541921377182, 0.015315095894038677, -0.07262731343507767, 0.009323105216026306, 0.027024831622838974, -0.03334426134824753, 0.013657812029123306, -0.00958671048283577, 0.027750631794333458, -0.044428080320358276, 0.004604221787303686, -0.0045226579532027245, -0.032019734382629395, 0.06863954663276672, 0.04008687287569046, -0.0072461823001503944, 0.060473110526800156, 0.030102981254458427, -0.03917903080582619, -0.0076102642342448235, -0.022746864706277847, -0.029504846781492233, -0.023816650733351707, 0.009178891777992249, -0.0026072366163134575, -0.026320308446884155, 0.050722092390060425, -0.015958447009325027, 0.010174207389354706, -0.008376255631446838, -0.006231953389942646, 0.01980702020227909, 0.015011889860033989, 0.09929752349853516, 0.012259257957339287, -0.010078458115458488, -0.024923084303736687, 0.011560793034732342, -0.009222333319485188]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LangChain Retrievers\n",
    "Retrievers in LangChain are used to fetch relevant documents or information based on a user query. </br>\n",
    "They can be used to retrieve documents from various sources, such as databases, web pages, or vector stores. </br>\n",
    "\n",
    "### Types of Retrievers\n",
    "- **Vector Store Retriever**: Retrieves documents based on similarity search in a vector store.\n",
    "- **Document Loader Retriever**: Retrieves documents from a document loader.\n",
    "- **Multi-Query Retriever**: Retrieves documents based on multiple queries.\n",
    "- **EnsembleRetriever**: Combines results from multiple retrievers.\n",
    "\n",
    "### Reranking\n",
    "Reranking is a technique used to improve the quality of retrieved documents by reordering them based on relevance to the user query. </br>\n",
    "Reranking can be done using various methods, such as:\n",
    "- **Embedding-based Reranking**: Uses embeddings to calculate similarity between the query and retrieved documents.\n",
    "- **LLM-based Reranking**: Uses a language model to evaluate the relevance of retrieved documents based on the user query.\n",
    "- **Rule-based Reranking**: Uses predefined rules to reorder retrieved documents based on specific criteria.\n",
    "- **Metadata-based Reranking**: Uses metadata associated with documents to reorder them based on relevance to the user query.\n",
    "\n",
    "References:\n",
    "- https://python.langchain.com/docs/concepts/retrievers/\n"
   ],
   "id": "38f3d6c794950076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:47:11.743039Z",
     "start_time": "2025-05-29T13:47:11.559877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def format_docs_for_context(docs: List[Document]) -> str:\n",
    "    \"\"\"\n",
    "    Formats the retrieved documents into a single string for the prompt context.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n-----------\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# --- 6. Create Retriever and RAG Chain ---\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})  # Retrieve top 4 relevant chunks\n",
    "\n",
    "print(format_docs_for_context(retriever.invoke(\"What do you know about Tool use?\")))"
   ],
   "id": "71a8357c47cb4d6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\n",
      "\n",
      "Check more MIPS algorithms and performance comparison in ann-benchmarks.com.\n",
      "Component Three: Tool Use#\n",
      "Tool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\n",
      "\n",
      "\n",
      "A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\n",
      "\n",
      "-----------\n",
      "Both TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the External APIs section of Prompt Engineering.\n",
      "ChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\n",
      "HuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\n",
      "\n",
      "-----------\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview of a LLM-powered autonomous agent system.\n",
      "\n",
      "-----------\n",
      "package/project.\n",
      "Python toolbelt preferences:\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LangChain Chains\n",
    "\n",
    "Chains in LangChain allow you to create complex workflows by chaining together multiple operations, such as document retrieval, text processing, and LLM generation. </br>\n",
    "In the following steps, we will create a Retrieval-Augmented Generation (RAG) chain that retrieves relevant documents based on a user query and generates an answer using an LLM.\n",
    "\n",
    "### LangChain Expression Language (LCEL) \"Pipe\" Operator\n",
    "\n",
    "LangChain leverages Python's ability to overload operators (specifically the __or__ method) to implement a functional \"pipe\" or \"chaining\" mechanism. </br>\n",
    "**How it works in LCEL:**</br>\n",
    "When you write `component_a` | `component_b`, it means \"take the output of `component_a` and pass it as the input to `component_b`.\" </br>\n",
    "It creates a sequence of operations where the result of one step flows directly into the next.\n",
    "This makes building complex LLM applications (like RAG chains) much more readable and modular.\n",
    "Each \"component\" in an LCEL chain (like retriever, prompt, llm, StrOutputParser) is typically an instance of a Runnable object. LangChain's Runnable classes define the __or__ method, which is what allows this chaining syntax to work.\n"
   ],
   "id": "8f96f974be3be969"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T13:47:12.900222Z",
     "start_time": "2025-05-29T13:47:11.755726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "print(\"\\nCreating retriever and RAG chain...\")\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs_for_context, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "print(\"RAG chain created.\")\n",
    "print(\"\\n--- Starting RAG Application (with AWS Bedrock Embeddings and LLM) ---\")\n",
    "\n",
    "# example_question = \"What are the main components of an LLM agent?\"\n",
    "example_question = \"What can you tell me about Scientific Discovery Agent?\"  # https://lilianweng.github.io/posts/2023-06-23-agent/#component-two-memory\n",
    "\n",
    "final_answer = rag_chain.invoke(example_question)\n",
    "print(\"Question:\", example_question)\n",
    "print(\"Answer:\", final_answer)\n",
    "\n"
   ],
   "id": "3d5061c761a07233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating retriever and RAG chain...\n",
      "RAG chain created.\n",
      "\n",
      "--- Starting RAG Application (with AWS Bedrock Embeddings and LLM) ---\n",
      "Question: What can you tell me about Scientific Discovery Agent?\n",
      "Answer: Scientific Discovery Agent, like ChemCrow, uses LLMs augmented with expert tools for tasks in organic synthesis and drug discovery. It follows a CoT reasoning format and can outperform general LLMs in domain-specific tasks, though it has risks in sensitive areas like illicit drugs.\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
